account: "pas2136"
path_to_input: "/fs/scratch/PAS2136/gbif/data/file.csv"
#path_to_output_folder: "/fs/scratch/PAS2136/gbif/processed/2024-05-01/multimedia_prep"
path_to_output_folder: "/mnt/d/Projects/Python/ImUn/gbif"

scripts:
  # Wrapper scripts to submit jobs to the cluster
  general_submitter: "/users/PAS2119/andreykopanev/distributed-downloader/scripts/general_submit.sh"
  mpi_submitter: "/users/PAS2119/andreykopanev/distributed-downloader/scripts/submit_mpi_download.sh"
  schedule_creator_submitter: "/users/PAS2119/andreykopanev/distributed-downloader/scripts/submit_schedule_creator.sh"
  # Cluster job's scripts
  initialization_script: "/users/PAS2119/andreykopanev/distributed-downloader/scripts/initialization.slurm"
  profiling_script: "/users/PAS2119/andreykopanev/distributed-downloader/scripts/profiling.slurm"
  schedule_creation_script: "/users/PAS2119/andreykopanev/distributed-downloader/scripts/schedule_creation.slurm"
  verify_script: "/users/PAS2119/andreykopanev/distributed-downloader/scripts/verify_downloading.slurm"
  download_script: "/users/PAS2119/andreykopanev/distributed-downloader/scripts/server_downloading.slurm"
  # tools scripts
  resize_script: "/users/PAS2119/andreykopanev/distributed-downloader/scripts/resize_mpi.slurm"

# Rules for the schedule creation
# They determine how many simultaneous downloader instances can be run on the same server
# Rules are based on the number of batches required to be downloaded from the server
# Rule is: key - number of batches, value - number of instances; if server has more than key batches, value instances can be run
# Server with 0 batches is considered to be downloaded and are ignored
# Default value is 1
# Order of the rules does not matter
schedule_rules:
  5000: 40
  1000: 20
  500: 10
  200: 8
  100: 4
  50: 2
  1: 1

# Structure of the output folder that will be created automatically
output_structure:
  urls_folder: "servers_batched"
  logs_folder: "logs"
  images_folder: "downloaded_images"
  schedules_folder: "schedules"
  profiles_table: "servers_profiles.csv"
  ignored_table: "ignored_servers.csv"
  inner_checkpoint_file: "inner_checkpoint.txt"

# Parameters for the downloader
downloader_parameters:
  num_downloads: 10
  max_nodes: 7
  workers_per_node: 6
  cpu_per_worker: 6
  header: "User-Agent: Imageomics Institute (https://imageomics.org; imageomics-it@osu.edu)"
  image_size: 720
  logger_level: "INFO"
  batch_size: 10000
